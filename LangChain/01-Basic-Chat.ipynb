{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277ee83f",
   "metadata": {},
   "source": [
    "## Build AI Applications using LangChain\n",
    "\n",
    "### Plan\n",
    "In previous exercises, we used the OpenAI client library to call both OpenAI and nonâ€‘OpenAI models (Anthropic, Google, Mistral, etc.), and built different applications such as chat, summarization, audio transcription, text translation, etc. \n",
    "\n",
    "In this exercise, we will build Chatbot by using the LangChain library and OpenAI LLM. \n",
    "\n",
    "The LangChain library can not only call different LLMs, similar to the OpenAI client library, it can build an end-to-end AI system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed6c9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1208b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API keys of the LLMs stored as environment variables in .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# OpenAI API key\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Validate the OpenAI API key\n",
    "if not openai_api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not openai_api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif openai_api_key.strip() != openai_api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"OpenAI API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff36d207",
   "metadata": {},
   "source": [
    "### Create Simple Chatbot with User Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0baec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ChatOpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", api_key=openai_api_key)\n",
    "\n",
    "# Define user prompt\n",
    "user_prompt = \"What is the capital of France?\"\n",
    "\n",
    "# Call the model\n",
    "response = model.invoke(user_prompt)\n",
    "\n",
    "# Print the entire response returned by the model\n",
    "print(response)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a51377",
   "metadata": {},
   "source": [
    "### Create Simple Chatbot with System and User Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f412ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"\"\"\n",
    "    You are a travel expert, who knows all about places around the world. \n",
    "    If the user asks about a place, you should provide brief information about the place.\n",
    "    If the user asks about anything else, you should say that you can only answer travel related questions.\n",
    "    \"\"\"),\n",
    "    HumanMessage(content=\"What is the best place to see wildlife in the United States?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b2f694",
   "metadata": {},
   "source": [
    "### Create Simple Chatbot with Conversation Trail\n",
    "\n",
    "When we call the chat model for the first time, we pass the system prompt and the user prompt, and we get the response from the model. We can add that response into the messages list and the next user prompt and pass that new list to call the model. Then the model will answer the last question in context of the entire conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"\"\"\n",
    "    You are a travel expert, who knows all about places around the world. \n",
    "    If the user asks about a place, you should provide brief information about the place.\n",
    "    If the user asks about anything else, you should say that you can only answer travel related questions.\n",
    "    \"\"\"),\n",
    "    HumanMessage(content=\"What is the best place to see wildlife in the United States?\"),\n",
    "    AIMessage(content=\"The best place to see wildlife in the United States is Yellowstone National Park.\"),\n",
    "    HumanMessage(content=\"When is the best time to visit there to see the wildlife?\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
